# train.py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import glob
from model import ScalpingLSTM
from config import DEVICE

# [ì„¤ì •] ë°ì´í„°ê°€ ì ì–´ë„ í•™ìŠµë˜ë„ë¡ ì„¤ì •ê°’ ì¡°ì •
SEQ_LEN = 10  # ê³¼ê±° 10ê°œë¥¼ ë³´ê³  ë‹¤ìŒì„ ì˜ˆì¸¡
BATCH_SIZE = 16
EPOCHS = 50

class StockDataset(Dataset):
    def __init__(self, file_paths, seq_len=SEQ_LEN):
        self.samples = []
        self.seq_len = seq_len
        
        print(f"ğŸ“‚ í•™ìŠµ ë°ì´í„° ë¡œë”© ì¤‘... (íŒŒì¼ {len(file_paths)}ê°œ ê°ì§€)")
        
        for path in file_paths:
            try:
                # 1. CSV ì½ê¸°
                df = pd.read_csv(path)
                
                # ë°ì´í„°ê°€ í…… ë¹„ì—ˆê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ íŒ¨ìŠ¤
                if len(df) < seq_len + 1:
                    continue

                # ë¬¸ìì—´ì„ ìˆ«ìë¡œ ê°•ì œ ë³€í™˜ (ì—ëŸ¬ ë°©ì§€)
                cols = ['stck_prpr', 'stck_oprc', 'stck_hgpr', 'stck_lwpr', 'cntg_vol']
                for col in cols:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # NaN(ë¹ˆê°’) ì œê±°
                df = df.dropna()

                # ì‹œê°„ ìˆœì„œ ì •ë ¬ (ì¼ë´‰ì€ ì—­ìˆœìœ¼ë¡œ ë“¤ì–´ì˜¤ë¯€ë¡œ ë’¤ì§‘ê¸°)
                df = df.iloc[::-1].reset_index(drop=True)

                # 4. ì •ê·œí™” (Normalization)
                price_data = df[['stck_prpr', 'stck_oprc', 'stck_hgpr', 'stck_lwpr']].values
                volume_data = df[['cntg_vol']].values
                
                price_max = price_data.max()
                price_min = price_data.min()
                vol_max = volume_data.max()
                
                if price_max == price_min or vol_max == 0:
                    continue

                scaled_price = (price_data - price_min) / (price_max - price_min + 1e-8)
                scaled_vol = volume_data / (vol_max + 1e-8)
                
                # í•©ì¹˜ê¸° (5ê°œ í”¼ì³)
                data = np.hstack([scaled_price, scaled_vol])
                
                # 5. ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
                for i in range(len(data) - seq_len):
                    x = data[i : i+seq_len]      # ê³¼ê±° 10ì¼ì¹˜
                    y = data[i+seq_len][0]       # ë‹¤ìŒë‚  ì¢…ê°€(í˜„ì¬ê°€) ì˜ˆì¸¡
                    
                    self.samples.append((
                        torch.FloatTensor(x), 
                        torch.FloatTensor([y])
                    ))
                    
            except Exception as e:
                print(f"âš ï¸ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ({path}): {e}")
                continue

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        return self.samples[idx]

def train():
    print(f"ğŸ”¥ í•™ìŠµ ì‹œì‘ (Device: {DEVICE})")
    
    file_list = glob.glob("data/raw/*.csv")
    if not file_list:
        print("âŒ 'data/raw' í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    dataset = StockDataset(file_list)
    
    if len(dataset) == 0:
        print("âš ï¸ ìœ íš¨í•œ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„° ë¶€ì¡± ë˜ëŠ” í˜•ì‹ ì˜¤ë¥˜)")
        return

    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
    print(f"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ! (ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset)}ê°œ)")

    # [í•µì‹¬ ìˆ˜ì •] ë³€ìˆ˜ëª… ì§€ì • ì—†ì´ ìˆœì„œëŒ€ë¡œ ê°’ë§Œ ì „ë‹¬ (ìœ„ì¹˜ ì¸ì ì‚¬ìš©)
    # ScalpingLSTM(input_size, hidden_size, num_layers, output_size) ìˆœì„œë¼ê³  ê°€ì •
    # ì—ëŸ¬ê°€ ë‚˜ì§€ ì•Šê²Œ ê°€ì¥ ì¼ë°˜ì ì¸ ìˆœì„œë¡œ ê°’ì„ ë„£ìŠµë‹ˆë‹¤.
    # (ì…ë ¥ì°¨ì›: 5, ì€ë‹‰ì¸µ: 32, ë ˆì´ì–´ìˆ˜: 2, ì¶œë ¥ì°¨ì›: 1)
    try:
        model = ScalpingLSTM(5, 32, 2, 1).to(DEVICE)
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì—ëŸ¬: {e}")
        print("ğŸ’¡ model.pyì˜ __init__ í•¨ìˆ˜ ì¸ì ìˆœì„œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()

    model.train()
    
    for epoch in range(EPOCHS):
        total_loss = 0
        for x, y in dataloader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            
            optimizer.zero_grad()
            output = model(x)
            loss = criterion(output, y)
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
        if (epoch+1) % 10 == 0:
            avg_loss = total_loss / len(dataloader)
            print(f"Epoch [{epoch+1}/{EPOCHS}] Loss: {avg_loss:.6f}")

    torch.save(model.state_dict(), "scalping_model.pth")
    print("ğŸ‰ í•™ìŠµ ì™„ë£Œ! 'scalping_model.pth' ì €ì¥ë¨.")

if __name__ == "__main__":
    train()